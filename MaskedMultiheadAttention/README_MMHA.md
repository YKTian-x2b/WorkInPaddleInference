# 最终结果

> https://github.com/PaddlePaddle/Paddle/pull/62838
> LightVersion: https://github.com/PaddlePaddle/Paddle/pull/63987

- split seq_len to improve mmha perf, with mmhaKernel optimazation and postProcessKernel.



- facebook/llama-7b: dynamic Inference，_infer() endToEnd，--benchmark，warmup\*1，test\*5， avgCost(ms)：

| max_length & batch | ***baseline*** | 当前      | speedup      |
| ------------------ | -------------- | --------- | ------------ |
| 1024 & 1           | 14338          | **13845** | **(+3.5%)**  |
| 1024 & 2           | 14471          | **14414** | **(+0.3%)**  |
| 1024 & 4           | 14792          | **14524** | **(+1.8%)**  |
| 1024 & 8           | **15485**      | 15514     | **(-0.18%)** |
| 2048 & 1           | 28384          | **27784** | **(+2.1%)**  |
| 2048 & 2           | 29170          | **29000** | **(+0.5%)**  |
| 3072 & 1           | 43776          | **42666** | **(+2.6%)**  |

- meta-llama/Llama-2-7b-chat: dy&st MIX Inference(decorator)，nlp benchmark，warmup\*2，test\*10， avgCost(s)：

| max_length & batch | ***baseline*** | **当前** | speedup      |
| ------------------ | -------------- | -------- | ------------ |
| 1024 & 1           | 15.7           | **13.9** | **(+12.9%)** |
| 1024 & 2           | 16.4           | **15.0** | **(+9.3%)**  |
| 1024 & 4           | 17.8           | **17.5** | **(+1.7%)**  |
| 1024 & 8           | 19.7           | **19.6** | **(+0.5%)**  |
| 2048 & 1           | 30.0           | **28.7** | **(+4.5%)**  |
| 2048 & 2           | 30.5           | **30.3** | **(+0.6%)**  |
| 3072 & 1           | 44.4           | **42.5** | **(+4.4%)**  |

﻿





# 散碎过程

- 是否优化_ThreadsPerKey_ThreadsPerBlock_StepsPerBlock
  - 5次实验取均值
- 短seq 2050 结果：

| Head_dim | 优化前_2_128 | 优化前_4_128 | 优化前_4_256 | 优化后2_128_64 | 优化后_4_128_64 | 优化后4_256_64 | 优化后_2_128_128 | 优化后_4_128_128 | 优化后_4_256_128 |
| -------- | ------------ | ------------ | ------------ | -------------- | --------------- | -------------- | ---------------- | ---------------- | ---------------- |
| 16       | 2.59         | **2.14**     | 2.57         | 2.80           | 3.32            | 3.87           | 2.42             | 2.90             | 2.94             |
| 32       | 2.37         | **2.29**     | 2.31         | 2.82           | 3.49            | 3.81           | 2.49             | 3.15             | 2.94             |
| 64       | 4.42         | **4.23**     | 4.74         | 5.21           | 5.12            | 6.09           | 4.55             | 4.90             | 5.15             |
| 80       | 6.27         | 6.26         | 6.27         | 5.87           | 6.35            | 7.08           | **5.27**         | 6.17             | 6.08             |
| 96       | 6.72         | 6.7          | 6.70         | 6.30           | 6.32            | 7.23           | **5.94**         | 6.11             | 6.55             |
| 128      | 7.87         | 7.86         | 7.87         | 7.60           | **7.49**        | 7.97           | 7.54             | 7.50             | 7.74             |
| 192      | 13.25        | 13.1         | 13.64        | 11.64          | **10.3**        | 11.93          | 11.57            | 12.46            | 10.90            |

- 长seq 10200 结果：
  - 2_128_128直接不能运行，操作系统报错
  - 4_256_64部分结果是错的（head_dim 小的时候）
  - 4_128_64部分结果是错的
  - 2_128_64部分结果是错的

| Head_dim | 优化前_2_128 | 前_4_128 | 前_4_256 | 优化后2_128_64 | 后_4_128_64 | 后4_256_64 | 后2_128_128 | 后_4_128_128 | 后4_256_128 |
| -------- | ------------ | -------- | -------- | -------------- | ----------- | ---------- | ----------- | ------------ | ----------- |
| 16       | 10.19        | 10.20    | 10.18    | 9.38           | 10.21       | 14.61      |             | **8.14**     | 9.78        |
| 32       | 11.69        | 11.64    | 11.70    | 10.48          | 11.05       | 14.83      |             | **9.5**      | 10.52       |
| 64       | 17.83        | 17.79    | 17.77    | 16.40          | 16.27       | 19.40      |             | 16.22        | **15.86**   |
| 80       | 25.75        | 25.76    | 25.70    | 21.62          | 21.13       | 26.28      |             | **19.79**    | 21.75       |
| 96       | 27.54        | 27.54    | 27.50    | 23.68          | 23.43       | 27.76      |             | **22.37**    | 23.69       |
| 128      | 31.22        | 31.16    | 31.11    | 29.36          | 28.90       | 31.04      |             | **27.77**    | 28.15       |
| 192      | 60.50        | 60.09    | 60.60    | 47.8852        | 43.63       | 50.74      |             | **42.11**    | 45.49       |

### Post_process_kernel优化

- 当前kernel在seq为204800时会报错，102400及以下正常
- ThreadsPerKey_ThreadsPerBlock_StepsPerBlock == 4_128_128
- 短seq 2050结果：

| Head_dim | split优化前 | Post_process_kernel_V2 | Post_process_kernel_V3 |
| -------- | ----------- | ---------------------- | ---------------------- |
| 16       | **2.14**    | 3.26                   | 2.93                   |
| 32       | **2.29**    | 3.16                   | 2.74                   |
| 64       | **4.23**    | 4.95                   | 4.89                   |
| 80       | 6.26        | **5.90**               | 5.98                   |
| 96       | 6.7         | 6.44                   | **6.34**               |
| 128      | 7.86        | 7.59                   | **7.54**               |
| 192      | 13.1        | 10.01                  | **9.9608**             |

- 长seq 10200结果：

| Head_dim | split优化前 | Post_process_kernel_V2 | Post_process_kernel_V3 |
| -------- | ----------- | ---------------------- | ---------------------- |
| 16       | 10.18       | 7.86                   | **6.94**               |
| 32       | 11.70       | 9.55                   | **8.64**               |
| 64       | 17.77       | 15.28                  | **14.55**              |
| 80       | 25.70       | 19.81                  | **19.00**              |
| 96       | 27.50       | 22.33                  | **21.53**              |
| 128      | 31.11       | 27.71                  | **26.97**              |
| 192      | 60.60       | 42.21                  | **41.48**              |

### 再次调参+优化解决超短seq劣化问题

- 用Post_process_kernel_v3
- ThreadsPerKey_ThreadsPerBlock_StepsPerBlock == 4_128_128
- 短seq 2050结果：

| Head_dim | split优化前 | 调参     | 优化     |
| -------- | ----------- | -------- | -------- |
| 16       | **2.14**    | 2.49     | 2.47     |
| 32       | **2.29**    | 2.51     | 2.50     |
| 64       | **4.23**    | 4.90     | 4.90     |
| 80       | 6.26        | **5.75** | 5.84     |
| 96       | 6.7         | **6.33** | 6.40     |
| 128      | 7.86        | 7.50     | **7.50** |
| 192      | 13.1        | 9.95     | **9.91** |

- 长seq 10200结果：

| Head_dim | split优化前 | 调参      | 优化      |
| -------- | ----------- | --------- | --------- |
| 16       | 10.18       | 7.14      | **6.94**  |
| 32       | 11.70       | 8.67      | **8.60**  |
| 64       | 17.77       | 14.59     | **14.54** |
| 80       | 25.70       | **19.13** | 19.33     |
| 96       | 27.50       | **21.63** | 21.83     |
| 128      | 31.11       | 27.02     | **26.99** |
| 192      | 60.60       | 41.55     | **41.39** |

### Bloom_7B1优化效果

- batch = 1

| seq_len | 优化前 | 优化后     |
| ------- | ------ | ---------- |
| 1024    | 94389  | **82968**  |
| 2048    | 198739 | **192811** |
| 3072    | 463991 | **353882** |

- batch = 2

| seq_len | 优化前     | 优化后    |
| ------- | ---------- | --------- |
| 1024    | 110210     | **96269** |
| 2048    | **296495** | 309886    |

### Bloom_7B1重新测试

- batch = 1

| seq_len | 优化前    | before_light      | 优化后    | after_light    |
| ------- | --------- | ----------------- | --------- | -------------- |
| 1024    | 26333     | 27149             | **25470** | 26924 (-2.1%)  |
| 2048    | **53111** | 56377             | 53610     | 54842 (-3.1%)  |
| 3072    | 100186    | (100559+105699)/2 | **85553** | 90179 (+11.0%) |

- batch = 2

| seq_len | 优化前    | before_light | 优化后    | after_light   |
| ------- | --------- | ------------ | --------- | ------------- |
| 1024    | 27702     | 30976        | **26675** | 27630 (+0.2%) |
| 2048    | **61943** | 62868        | 63044     | 64625 (-4.1%) |

- batch=4

| seq_len | 优化前 | before_light | 优化后    | after_light   |
| ------- | ------ | ------------ | --------- | ------------- |
| 1024    | 31972  | 33333        | **31471** | 31784 (+0.5%) |

- batch=8

| seq_len | 优化前    | before_light | 优化后 | after_light    |
| ------- | --------- | ------------ | ------ | -------------- |
| 1024    | **37683** | 38121        | 39780  | 41999 (-10.2%) |

### Bloom_7B1 Final

- pr 62838，表为第一次commit的结果

| seq_len & batch | 优化前 | 优化后    | SpeedUp   |
| --------------- | ------ | --------- | --------- |
| 1024 & 1        | 26333  | **25470** | **3.3%**  |
| 1024 & 2        | 27702  | **26675** | **3.8%**  |
| 1024 & 4        | 31972  | **31471** | **1.5%**  |
| 1024 & 8        | 37683  | 39780     | **-5.2%** |
| 2048 & 1        | 53111  | 53610     | **-0.9%** |
| 2048 & 2        | 61943  | 63044     | **-1.7%** |
| 3072 & 1        | 100186 | **85553** | **17.1%** |

- 多batch 或 短seq下，flashDecoding存在劣化问题。
- 如果想弥补短seq下的劣化问题，需要在CPU端（低耗时的情况下）拿到每个batch的sequence_lengths.
  - 但是sequence_lengths和src_mask都是可选的，且都在GPU端。不好改API，***非战之罪，可惜！***
- 8batch性能劣化 在进行上述改进后，还得分析。

### Bloom_7B1_Revive

| seq_len & batch | 优化前_right | 优化后(第一块512) | 优化后(第一块256)              |
| --------------- | ------------ | ----------------- | ------------------------------ |
| 1024 & 1        | **30069**    | 31867 **-6.8%**   | 31122 **(****-3.3%)**          |
| 1024 & 2        | **31018**    | 35151 **-7.9%**   | 30320 **(+2.3%)**              |
| 1024 & 4        | **34264**    | 38813 **-11.2%**  | 34732 **(-1.3%****)**          |
| 1024 & 8        | **40618**    | 44030 **-4.3%**   | 43215 **(-6.0%****)**          |
| 2048 & 1        | 72200        | 67649 **10.9%**   | **60013** **(+****20.3%****)** |
| 2048 & 2        | 79138        | 76447 **5.1%**    | **70215** **(+12.7**%**)**     |
| 3072 & 1        | 120886       | 99394 **22.3%**   | **95049** **(+27.1%)**         |

### Bloom_7B1_510

| seq_len & batch | 优化前 | 优化后_dirty | 优化后_dirty_postV2 | 优化后_cleaner | 优化后_cleaner_postV2 | 2_128     |
| --------------- | ------ | ------------ | ------------------- | -------------- | --------------------- | --------- |
| 1024 & 1        | 30717  | 31178        | **30278**           | 30599          | 30564                 | 30651     |
| 1024 & 2        | 33104  | 29820        | 30957               | 29882          | **29282**             | 29991     |
| 1024 & 4        | 35353  | **33906**    | 35280               | 35611          | 33994                 | 33993     |
| 1024 & 8        | **-**  | -            | -                   | -              | -                     | -         |
| 2048 & 1        | 72904  | 59731        | 60834               | 59267          | **59003**             | 60623     |
| 2048 & 2        | 78384  | 70546        | 68802               | 69240          | 68488                 | **68185** |
| 3072 & 1        | 121728 | **96866**    | 97432               | 97587          | 98730                 | 97242     |

| seq_len & batch | 优化后_**dirty** | 优化后_**cleaner** |
| --------------- | ---------------- | ------------------ |
| 1024 & 1        | 31178            | **30599**          |
| 1024 & 2        | **29820**        | 29882              |
| 1024 & 4        | **33906**        | 35611              |
| 1024 & 8        | -                | -                  |
| 2048 & 1        | 59731            | **59267**          |
| 2048 & 2        | 70546            | **69240**          |
| 3072 & 1        | **96866**        | 97587              |

| seq_len & batch | 优化后_**dirty** | 优化后_**dirty_postV2** |
| --------------- | ---------------- | ----------------------- |
| 1024 & 1        | 31178            | **30278**               |
| 1024 & 2        | **29820**        | 30957                   |
| 1024 & 4        | **33906**        | 35280                   |
| 1024 & 8        | -                | -                       |
| 2048 & 1        | **59731**        | 60834                   |
| 2048 & 2        | 70546            | **68802**               |
| 3072 & 1        | **96866**        | 97432                   |

| seq_len & batch | 优化后_**dirty** | **2_128** |
| --------------- | ---------------- | --------- |
| 1024 & 1        | 31178            | **30651** |
| 1024 & 2        | **29820**        | 29991     |
| 1024 & 4        | **33906**        | 33993     |
| 1024 & 8        | -                | -         |
| 2048 & 1        | **59731**        | 60623     |
| 2048 & 2        | 70546            | **68185** |
| 3072 & 1        | **96866**        | 97242     |

### 当前

- 经过考虑 我们还是选择 ***优化后_dirty*** 这个版本，它没有cleaner版本的代码简单，postV3比postV2占用了更多的线程。但是性能无明显缺陷，长seq表现最佳。

| seq_len & batch | 优化前    | 优化后_dirty |
| --------------- | --------- | ------------ |
| 1024 & 1        | **30717** | 31178        |
| 1024 & 2        | 33104     | **29820**    |
| 1024 & 4        | 35353     | **33906**    |
| 1024 & 8        | **-**     | -            |
| 2048 & 1        | 72904     | **59731**    |
| 2048 & 2        | 78384     | **70546**    |
| 3072 & 1        | 121728    | **96866**    |

### 待解决的问题

- 256000Seq + 128Dh + 2Batch   mmha直接报错的问题
  - 即使只跑<256Seq（不进后处理）也会报错，是mmha直接报错。
  - 是否需要解决
- 改宏
- 其余代码处理

### 620

![img](https://rte.weiyun.baidu.com/wiki/attach/image/api/imageDownloadAddress?attachId=2d14bdd2e9794a75a00adb2f298aa94e&docGuid=0aQBV-jaHTtAvS)

- 1024prompt + 256token生成
- mmha算子跑十遍的端到端

| seq_len & batch | 优化前      | 优化后_dirty    |
| --------------- | ----------- | --------------- |
| 1024 & 1        | 1735.4462ms | **1259.3662ms** |

- seq_lens: [1278],      before_time_cost: 0.590ms
- seq_lens: [1278],      after_time_cost: 0.274ms

### 625

- --dtype float16 --src_length 1024 --max_length 1024  --batch_size 1 --inference
- mmha算子跑十遍 + 端到端5次循环 + 耗时均值
  - 预测了两句话，所以有两个结果

| seq_len & batch | 优化前                    | 模板优化的非split版      | 非模板优化 |
| --------------- | ------------------------- | ------------------------ | ---------- |
| 1024 & 1        | **8323.6576**             | 8406.7638   **(-0.98%)** | 10029.249  |
| **1335.456**    | 1359.803     **(-1.79%)** | 1578.202                 |            |

### 705

| seq_len & batch | 优化前              | 625                 | False_704_2128      | False_704_4128       | True                |
| --------------- | ------------------- | ------------------- | ------------------- | -------------------- | ------------------- |
| 1024 & 1        | 9366                | 9151   **(+2.34%)** | 8923   **(+4.96%)** | 9311   **(+0.59%)**  | 9603   **(-2.46%)** |
| 8705            | 8856   **(-1.70%)** | 9296   **(-6.35%)** | 9034   **(-3.64%)** | 10237   **(-14.9%)** |                     |

### 708

| seq_len & batch | 优化前             | False_708_2128 | False_708_4128 | False_708_4256 | True  | 备注   |
| --------------- | ------------------ | -------------- | -------------- | -------------- | ----- | ------ |
| 1024 & 1        | 8596  **(-3.58%)** | 8916           | 9550           | 9267           | 9784  |        |
| 2048 & 1        | 9109               | 8569           | 8762           | 8939           | 10344 | 不合理 |
| 3072 & 1        | 8851               | 10326          | 10001          | 8813           | 10223 | 不合理 |

| seq_len & batch | 优化前       | False_704_2128 |
| --------------- | ------------ | -------------- |
| 1024 & 1        | 8841         | 9215 **()**    |
| 11529           | 8980  **()** |                |
| 9489            | 8965         |                |
|                 | 8942         | 8594           |

### 709

- 在nlp里加上 ***attn_mask = attn_mask[:,:,:,:paddle.max(seq_lens, axis=0)+1]***

| seq_len & batch | 优化前 | 优化后 | speedup          |
| --------------- | ------ | ------ | ---------------- |
| 1024 & 1        | 35327  | 34826  | **(+1.4****%)**  |
| 1024 & 2        | 37962  | 35945  | **(+5.6****%)**  |
| 1024 & 4        | 40884  | 39872  | **(+2.5****%)**  |
| 1024 & 8        | 47671  | 47173  | **(+1.0****%)**  |
| 2048 & 1        | 83239  | 70024  | **(+18.8****%)** |
| 2048 & 2        | 91327  | 77479  | **(+17.8****%)** |
| 3072 & 1        | 129885 | 107933 | **(+20.3****%)** |

### 709下午

- 在nlp里加上 ***attn_mask = attn_mask[:,:,:,:paddle.max(seq_lens, axis=0)+1]***

| seq_len & batch | 优化前 | 优化后 | speedup          |
| --------------- | ------ | ------ | ---------------- |
| 1024 & 1        | 36624  | 31936  | **(+14.6****%)** |
| 1024 & 2        | 37630  | 33446  | **(+12.5****%)** |
| 1024 & 4        | 39324  | 37103  | **(+5.9****%)**  |
| 1024 & 8        | 45643  | 45222  | **(+0.9****%)**  |
| 2048 & 1        | 79268  | 64813  | **(+22.3****%)** |
| 2048 & 2        | 86543  | 74910  | **(+15.5****%)** |
| 3072 & 1        | 122132 | 100512 | **(+21.5****%)** |

- 不加

| seq_len & batch | 优化前 | 优化后 | speedup          |
| --------------- | ------ | ------ | ---------------- |
| 1024 & 1        | 33812  | 30208  | **(+11.9****%)** |
| 1024 & 2        | 36951  | 31173  | **(+18.5****%)** |
| 1024 & 4        | 40648  | 36432  | **(+11.5****%)** |
| 1024 & 8        | 46477  | 45948  | **(+1.15****%)** |
| 2048 & 1        | 59858  | 58376  | **(+2.5****%)**  |
| 2048 & 2        | 68209  | 68579  | **(-0.5****%)**  |
| 3072 & 1        | 110270 | 96743  | **(+13.9****%)** |

- 优化后，加和不加的对比

| seq_len & batch | 默认超长(不加) | max(seq_lens)(加) | speedup         |
| --------------- | -------------- | ----------------- | --------------- |
| 1024 & 1        | 30208          | 31936             | **(-5.4****%)** |
| 1024 & 2        | 31173          | 33446             | **(-6.7****%)** |
| 1024 & 4        | 36432          | 37103             | **(-1.8****%)** |
| 1024 & 8        | 45948          | 45222             | **(+1.6****%)** |
| 2048 & 1        | 58376          | 64813             | **(-9.9****%)** |
| 2048 & 2        | 68579          | 74910             | **(-8.4****%)** |
| 3072 & 1        | 96743          | 100512            | **(-3.7****%)** |

### **710**

- _infer()端到端，--benchmark，warmup*1，run*5， 均值
- nlp加max(seq_lens)

| seq_len & batch | 优化前 | 优化后 | speedup      |
| --------------- | ------ | ------ | ------------ |
| 1024 & 1        | 18120  | 15323  | **(+18.2%)** |
| 1024 & 2        | 18104  | 16850  | **(+7.4%)**  |
| 1024 & 4        | 17699  | 18183  | **(-2.6%)**  |
| 1024 & 8        | 20611  | 17517  | **(+17.6%)** |
| 2048 & 1        | 41125  | 30395  | **(+35.3%)** |
| 2048 & 2        | 38490  | 31026  | **(+24.0%)** |
| 3072 & 1        | 47794  | 48474  | **(-1.4%)**  |

- nlp不加任何东西，就是原样

| seq_len & batch | 优化前 | 优化后 | speedup      |
| --------------- | ------ | ------ | ------------ |
| 1024 & 1        | 15547  | 14518  | **(+7.0%)**  |
| 1024 & 2        | 15050  | 14874  | **(+1.1%)**  |
| 1024 & 4        | 15223  | 14800  | **(+2.8%)**  |
| 1024 & 8        | 17025  | 15741  | **(+8.1%)**  |
| 2048 & 1        | 28854  | 28254  | **(+2.1%)**  |
| 2048 & 2        | 29539  | 29534  | **(+0.01%)** |
| 3072 & 1        | 47705  | 44276  | **(+7.74%)** |

- 汇总一下：

| seq_len & batch | 加max(seq_lens)_优化前 | 加max(seq_lens)_优化后 | 不加_优化前 | 不加_优化后 |
| --------------- | ---------------------- | ---------------------- | ----------- | ----------- |
| 1024 & 1        | 18120                  | 15323                  | 15547       | **14518**   |
| 1024 & 2        | 18104                  | 16850                  | 15050       | **14874**   |
| 1024 & 4        | 17699                  | 18183                  | 15223       | **14800**   |
| 1024 & 8        | 20611                  | 17517                  | 17025       | **15741**   |
| 2048 & 1        | 41125                  | 30395                  | 28854       | **28254**   |
| 2048 & 2        | 38490                  | 31026                  | 29539       | **29534**   |
| 3072 & 1        | 47794                  | 48474                  | 47705       | **44276**   |

### 715

- 6.20的版本，没有加入SPLIT模板参数
- _infer()端到端，--benchmark，warmup*1，run*5， 均值

- nlp不加任何东西，就是原样

| seq_len & batch | 优化前 | 优化后_620 | speedup     |
| --------------- | ------ | ---------- | ----------- |
| 1024 & 1        | 15562  | 14501      | **(+7.3%)** |
| 1024 & 2        | 15236  | 14336      | **(+6.2%)** |
| 1024 & 4        | 15400  | 14676      | **(+4.9%)** |
| 1024 & 8        | 15980  | 15904      | **(+0.4%)** |
| 2048 & 1        | 31004  | 29908      | **(+3.6%)** |
| 2048 & 2        | 29598  | 30099      | **(-1.6%)** |
| 3072 & 1        | 45428  | 43126      | **(+5.3%)** |

- nlp加 ***attn_mask = attn_mask[:,:,:,:paddle.max(seq_lens, axis=0)+1]***
  - 这个加的不好 会延迟到for循环里执行

| seq_len & batch | 优化前    | 优化后_620 | speedup      |
| --------------- | --------- | ---------- | ------------ |
| 1024 & 1        | **15253** | 15843      | **(-3.7%)**  |
| 1024 & 2        | 16501     | **14857**  | **(+11.0%)** |
| 1024 & 4        | 15853     | **14864**  | **(+6.6%)**  |
| 1024 & 8        | **16929** | 16956      | **(-0.1%)**  |
| 2048 & 1        | 33723     | **29174**  | **(+15.5%)** |
| 2048 & 2        | 32228     | **30308**  | **(+6.3%)**  |
| 3072 & 1        | 47614     | **44975**  | **(+5.8%)**  |

- nlp加 ***paddle.clone(attn_mask[:,:,:,:paddle.max(seq_lens, axis=0)+1])***

| seq_len & batch | 优化前 | 优化后_620 | speedup     |
| --------------- | ------ | ---------- | ----------- |
| 1024 & 1        | 14829  | 14733      | **(+0.6%)** |
| 1024 & 2        | 15389  | 15130      | **(+1.7%)** |
| 1024 & 4        | 15178  | 16675      | **(-8.9%)** |
| 1024 & 8        | 15928  | 17068      | **(-6.6%)** |
| 2048 & 1        | 31273  | 30955      | **(+1.0%)** |
| 2048 & 2        | 30992  | 31338      | **(-1.1%)** |
| 3072 & 1        | 47281  | 43541      | **(+8.5%)** |

- 汇总一下：

| seq_len & batch | 加***clone_attn_mask***_优化前 | 加***clone_attn_mask***_优化后_620 | 加***clone_attn_mask***_优化后_710 | 不加_优化前 | 不加_优化后_620 | 不加_优化后_710 |
| --------------- | ------------------------------ | ---------------------------------- | ---------------------------------- | ----------- | --------------- | --------------- |
| 1024 & 1        | 14829                          | 14733                              | 14227                              | 15562       | 14501           | **14041**       |
| 1024 & 2        | 15389                          | 15130                              | 14630                              | 15236       | **14336**       | 14705           |
| 1024 & 4        | 15178                          | 16675                              | 15480                              | 15400       | **14676**       | 15120           |
| 1024 & 8        | 15928                          | 17068                              | 15936                              | 15980       | **15904**       | 15965           |
| 2048 & 1        | 31273                          | 30955                              | 28770                              | 31004       | 29908           | **28662**       |
| 2048 & 2        | 30992                          | 31338                              | 30431                              | **29598**   | 30099           | 30255           |
| 3072 & 1        | 47281                          | 43541                              | 44678                              | 45428       | **43126**       | 43879           |

- 710pr + 512后SPLIT

| seq_len & batch | 加***clone_attn_mask*** | 不加  | speedup |
| --------------- | ----------------------- | ----- | ------- |
| 1024 & 1        | 14694                   | 13845 |         |
| 1024 & 2        | 14656                   | 14414 |         |
| 1024 & 4        | 15662                   | 14524 |         |
| 1024 & 8        | 16291                   | 15514 |         |
| 2048 & 1        | 28445                   | 27784 |         |
| 2048 & 2        | 29484                   | 29000 |         |
| 3072 & 1        | 45483                   | 42666 |         |

### 716

| seq_len & batch | 加***clone_attn_mask***_优化前 | 加***clone_attn_mask***_优化后_v710 | 加***clone_attn_mask***_优化后_v710_512 | 不加_优化前 | 不加_优化后_v710 | 不加_优化后_v710_512 |
| --------------- | ------------------------------ | ----------------------------------- | --------------------------------------- | ----------- | ---------------- | -------------------- |
| 1024 & 1        | 14411                          | 14291                               | 14351                                   | 14338       | 13838            | **13845**            |
| 1024 & 2        | 14539                          | 14449                               | **14166**                               | 14471       | 14193            | 14414                |
| 1024 & 4        | 14804                          | 14671                               | 14867                                   | 14792       | 14536            | **14524**            |
| 1024 & 8        | 15661                          | 15596                               | 15756                                   | **15485**   | 15551            | 15514                |
| 2048 & 1        | 30181                          | 28447                               | 29421                                   | 28384       | 28191            | **27784**            |
| 2048 & 2        | 30856                          | 30225                               | 29396                                   | 29170       | 29539            | **29000**            |
| 3072 & 1        | 45911                          | 43407                               | 43189                                   | 43776       | 42836            | **42666**            |

- 当前最佳

| max_length & batch | ***baseline*** | 当前      | speedup      |
| ------------------ | -------------- | --------- | ------------ |
| 1024 & 1           | 14338          | **13845** | **(+3.5%)**  |
| 1024 & 2           | 14471          | **14414** | **(+0.3%)**  |
| 1024 & 4           | 14792          | **14524** | **(+1.8%)**  |
| 1024 & 8           | **15485**      | 15514     | **(-0.18%)** |
| 2048 & 1           | 28384          | **27784** | **(+2.1%)**  |
| 2048 & 2           | 29170          | **29000** | **(+0.5%)**  |
| 3072 & 1           | 43776          | **42666** | **(+2.6%)**  |

- 当前最佳的白天复现

| max_length & batch | ***baseline*** | 不改nlp_v710_512 | speedup     |
| ------------------ | -------------- | ---------------- | ----------- |
| 1024 & 1           | 14278          | **13835**        | **(+3.2%)** |
| 1024 & 2           | 14439          | **14284**        | **(+1.0%)** |
| 1024 & 4           | 14601          | 14690            | **(-0.6%)** |
| 1024 & 8           | 15585          | 15708            | **(-0.7%)** |
| 2048 & 1           | 28425          | **28059**        | **(+1.3%)** |
| 2048 & 2           | 30008          | **29022**        | **(+3.3%)** |
| 3072 & 1           | 43832          | **42909**        | **(+2.1%)** |

### 717

- 装饰器 动静混合推理
- nlp benchmark --src_length 1024

| max_length & batch | 加***clone_attn_mask***_优化前 | 加***clone_attn_mask***_优化后 | 不加_优化前 | 不加_优化后 |
| ------------------ | ------------------------------ | ------------------------------ | ----------- | ----------- |
| 1024 & 1           | 16.8                           | 14.7                           | 15.7        | **13.9**    |
| 1024 & 2           | 17.2                           | 16.4                           | 16.4        | **15.0**    |
| 1024 & 4           | **17.0**                       | 17.1                           | 17.8        | 17.5        |
| 1024 & 8           | **19.0**                       | 20.0                           | 19.7        | 19.6        |
| 2048 & 1           | 31.9                           | **28.2**                       | 30.0        | 28.7        |
| 2048 & 2           | 32.2                           | 31.8                           | 30.5        | **30.3**    |
| 3072 & 1           | 46.9                           | 44.0                           | 44.4        | **42.5**    |

- 当前最佳

| max_length & batch | ***baseline*** | **当前** | speedup      |
| ------------------ | -------------- | -------- | ------------ |
| 1024 & 1           | 15.7           | **13.9** | **(+12.9%)** |
| 1024 & 2           | 16.4           | **15.0** | **(+9.3%)**  |
| 1024 & 4           | 17.8           | **17.5** | **(+1.7%)**  |
| 1024 & 8           | 19.7           | **19.6** | **(+0.5%)**  |
| 2048 & 1           | 30.0           | **28.7** | **(+4.5%)**  |
| 2048 & 2           | 30.5           | **30.3** | **(+0.6%)**  |
| 3072 & 1           | 44.4           | **42.5** | **(+4.4%)**  |